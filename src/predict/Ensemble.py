'''
Created on Nov 3, 2016

@author: abhijit.tomar

Module for creating an ensmeble classifier by
combining RandomForestClassifier and KNeighborsClassifier
'''
import Load_Data
import pickle
import pandas as pd
import json
from predict import Get_Optimal
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

if __name__ == '__main__':
    # Load the training and test data
    X_train,y_train,X_test = Load_Data.load_data()
    # Initialize RandomForestClassifier using the optimal hyper-parameters generated by Predict_RForest module
    rf_clf=RandomForestClassifier()
    rf_param_map = json.load(open('../../resources/params/'+type(rf_clf).__name__+'_for_accuracy_params.json'))
    rf_clf = RandomForestClassifier(**rf_param_map)
    # Initialize KNeighborsClassifier using the optimal hyper-parameters generated by Predict_KNN module
    knn_clf=KNeighborsClassifier()
    knn_param_map = json.load(open('../../resources/params/'+type(knn_clf).__name__+'_for_accuracy_params.json'))
    knn_clf = KNeighborsClassifier(**knn_param_map)
    # Initialize VotingClassifier as a combination of KNeighborsClassifier and RandomForestClassifier
    ensemble_clf = VotingClassifier(estimators=[('rf',rf_clf),('knn',knn_clf)])
    # Set up possible values for hyper-parameters. These would be used by GridSearch to derive optimal set of hyper-parameters
    tuned_parameters = [{'voting': ['hard','soft'],'weights':[[1,2],[2,1]]}]
    # Initialize scoring metric for this problem space
    scores = ['accuracy']
    # Generate optimal set of hyper-parameters for the above classifier
    Get_Optimal.generate_optimal(X_train, y_train, ensemble_clf, tuned_parameters, scores)
    # Load the optimal hyper-parameters
    param_map = json.load(open('../../resources/params/'+type(ensemble_clf).__name__+'_for_accuracy_params.json'))
    # Add RandomForestClassifier and KNeighborsClassifier to the optimal hyper-parameter map
    param_map['estimators']=[('rf',rf_clf),('knn',knn_clf)]
    # Reinitialize the classifier but now with the optimal hyper-parameters
    ensemble_clf = VotingClassifier(**param_map)
    # Train the classifier
    ensemble_clf.fit(X_train, y_train)
    # Optionally, save the trained classifier  
    with open('../../resources/models/'+type(ensemble_clf).__name__+'_Model.pickle','wb') as fileName:
        pickle.dump(ensemble_clf,fileName)
    # Predict on the test data
    y_pred = ensemble_clf.predict(X_test)
    # Optionally, find out the prediction probabilities
    y_pred_prob = ensemble_clf.predict_proba(X_test)
    # Optionally, save the predictions
    with open('../../resources/predictions/'+type(ensemble_clf).__name__+'_y_pred.pickle','wb') as fileName:
        pickle.dump(y_pred,fileName)
    # Optionally, save the prediction probabilities
    with open('../../resources/predictions/'+type(ensemble_clf).__name__+'_y_pred_prob.pickle','wb') as fileName:
        pickle.dump(y_pred_prob,fileName)
    # Create the imgge ids column for submission 
    image_ids=[]
    for i in range(1,len(X_test)+1):
        image_ids.append(i)
    # Save the submission as CSV
    pd.DataFrame({'ImageId': image_ids, 'Label': y_pred}).to_csv('../../resources/results/'+type(ensemble_clf).__name__+'_Pred.csv', index=False)
    